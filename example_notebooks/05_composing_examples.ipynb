{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 5: Composing Examples\n",
    "\n",
    "In this notebook we will examine how we can use the elements we have encountered so far, in order to construct a examples which will allow us to train machine learning models with data generated in real time. This is a core functionality of GravyFlow.\n",
    "\n",
    "As usual, we begin by performing the relevent imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in imports\n",
    "from typing import List, Dict, Iterator\n",
    "from pathlib import Path\n",
    "\n",
    "# Dependency imports: \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.layouts import gridplot\n",
    "\n",
    "# Import the GravyFlow module.\n",
    "import gravyflow as gf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an example generator through composition\n",
    "\n",
    "We can combine all the elements we have seen so, noise generation, waveform generation, and waveform projection, and use MLy to create a custom Python generator.\n",
    "\n",
    "In order to scale the injection with respect to the noise we can use a `gf.ScalingMethod` object. GravyFlow supports scaling with SNR (`gf.ScalingTypes.SNR`), HRSS (`gf.ScalingTypes.HRSS`), and HPEAK (`gf.ScalingTypes.HPEAK`).\n",
    "\n",
    "- `value` : `Union[gf.Distribution, np.ndarray]`, Required\n",
    "  > The value or distribution to use to scale the injections, units vary depending on type parameter.\n",
    "\n",
    "- `type_` : `gf.ScalingTypes`, Required\n",
    "  > Type of scaling, one of either `gf.ScalingTypes.SNR`, `gf.ScalingTypes.HRSS`, or `gf.ScalingTypes.HPEAK`.\n",
    "\n",
    "Let us create a `gf.ScalingMethod` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scaling method object in order to scale the injection to the noise:\n",
    "scaling_method : gf.ScalingMethod = gf.ScalingMethod(\n",
    "    value=gf.Distribution(\n",
    "        value=20,\n",
    "        type_=gf.DistributionType.CONSTANT\n",
    "    ),\n",
    "    type_=gf.ScalingTypes.SNR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can set up all the other elements that we can use to compose or example generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-28 04:35:33,316 - INFO - Using previously created distribution strategy.\n",
      "/home/michael.norman/gravyflow/gravyflow/src/dataset/dataset.py:44: UserWarning: Noise is not REAL or PSEUDO-REAL, yet data obtainer is defined.\n",
      "  warn(\n",
      "/home/michael.norman/gravyflow/gravyflow/src/dataset/dataset.py:62: UserWarning: Whitening requested for WHITE NOISE.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "with gf.env():\n",
    "    # This object will be used to obtain real interferometer data based on specified parameters.\n",
    "    ifo_data_obtainer : gf.IFODataObtainer = gf.IFODataObtainer(\n",
    "        observing_runs=gf.ObservingRun.O3, # Specify the observing run (e.g., O3).\n",
    "        data_quality=gf.DataQuality.BEST,  # Choose the quality of the data (e.g., BEST).\n",
    "        data_labels=[                      # Define the types of data to include.\n",
    "            gf.DataLabel.NOISE, \n",
    "            gf.DataLabel.GLITCHES\n",
    "        ],\n",
    "        segment_order=gf.SegmentOrder.RANDOM, # Order of segment retrieval (e.g., RANDOM).\n",
    "        force_acquisition=True,               # Force the acquisition of new data.\n",
    "        cache_segments=False                  # Choose not to cache the segments.\n",
    "    )\n",
    "\n",
    "    # Initialize the noise generator wrapper:\n",
    "    # This wrapper will use the ifo_data_obtainer to generate real noise based on the specified parameters.\n",
    "    noise: gf.NoiseObtainer = gf.NoiseObtainer(\n",
    "        ifo_data_obtainer=ifo_data_obtainer, # Use the previously set up IFODataObtainer object.\n",
    "        noise_type=gf.NoiseType.WHITE,        # Specify the type of noise as REAL.\n",
    "        ifos=gf.IFO.L1 # Specify the interferometer (e.g., LIGO Livingston L1).\n",
    "    )\n",
    "\n",
    "    # Define a uniform distribution for the mass of the first object in solar masses.\n",
    "    mass_1_distribution_msun : gf.Distribution = gf.Distribution(\n",
    "        min_=10.0, \n",
    "        max_=60.0, \n",
    "        type_=gf.DistributionType.UNIFORM\n",
    "    )\n",
    "\n",
    "    # Define a uniform distribution for the mass of the second object in solar masses.\n",
    "    mass_2_distribution_msun : gf.Distribution = gf.Distribution(\n",
    "        min_=10.0, \n",
    "        max_=60.0, \n",
    "        type_=gf.DistributionType.UNIFORM\n",
    "    )\n",
    "\n",
    "    # Define a uniform distribution for the inclination of the binary system in radians.\n",
    "    inclination_distribution_radians : gf.Distribution = gf.Distribution(\n",
    "        min_=0.0, \n",
    "        max_=np.pi, \n",
    "        type_=gf.DistributionType.UNIFORM\n",
    "    )\n",
    "\n",
    "    # Initialize a PhenomD waveform generator with the defined distributions.\n",
    "    # This generator will produce waveforms with randomly varied masses and inclination angles.\n",
    "    phenom_d_generator : gf.WaveformGenerator = gf.cuPhenomDGenerator(\n",
    "        mass_1_msun=mass_1_distribution_msun,\n",
    "        mass_2_msun=mass_2_distribution_msun,\n",
    "        inclination_radians=inclination_distribution_radians,\n",
    "        scaling_method=scaling_method,\n",
    "        injection_chance=0.5 # Set so half produced examples will not contain this signal\n",
    "    )\n",
    "    \n",
    "    generator : Iterator = gf.data(       \n",
    "        noise_obtainer=noise,\n",
    "        waveform_generators=phenom_d_generator,\n",
    "        num_examples_per_batch=8,\n",
    "        input_variables=[\n",
    "            gf.ReturnVariables.WHITENED_ONSOURCE, \n",
    "        ],\n",
    "        output_variables=[\n",
    "            gf.ReturnVariables.INJECTIONS, \n",
    "            gf.ReturnVariables.WHITENED_INJECTIONS,\n",
    "            gf.ReturnVariables.INJECTION_MASKS\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similiarly to the individual elements, we can use this example generator as an iterator, and produce N examples for use to examine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-28 04:35:33,357 - INFO - Using previously created distribution strategy.\n"
     ]
    }
   ],
   "source": [
    "with gf.env():\n",
    "    # Generate a batch of examples using the composed generator.\n",
    "    input_data, output_data = next(generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print the output of the generator to examine its format, which values are returned will depend on which parameters we have requested in the input_variables, and output_variables field in our gf.data function. Both are returned in the form of a dictionary, which can easly be fed into a keras model if the inputs of the model are named similarly to the variable feilds, we will show an example of this later in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary to feed the model: \n",
      " {'WHITENED_ONSOURCE': <tf.Tensor: shape=(8, 1, 2048), dtype=float16, numpy=\n",
      "array([[[ 1.449  , -0.583  , -0.4434 , ..., -0.342  ,\n",
      "         -0.684  ,  1.166  ]],\n",
      "\n",
      "       [[ 1.047  ,  0.667  ,  2.09   , ..., -1.096  ,\n",
      "          0.1973 , -0.3337 ]],\n",
      "\n",
      "       [[-0.0856 , -0.6196 , -1.855  , ...,  0.2218 ,\n",
      "         -1.561  , -1.305  ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 1.01   ,  0.04883, -0.05887, ..., -1.151  ,\n",
      "          0.508  ,  0.2773 ]],\n",
      "\n",
      "       [[-1.113  ,  0.2135 ,  3.441  , ..., -0.311  ,\n",
      "          1.305  , -0.7114 ]],\n",
      "\n",
      "       [[-2.357  ,  1.281  , -1.204  , ..., -0.08777,\n",
      "         -0.6196 ,  0.3792 ]]], dtype=float16)>}\n",
      "Dictionary to use as the model labels: \n",
      " {'INJECTIONS': <tf.Tensor: shape=(8, 1, 2048), dtype=float32, numpy=\n",
      "array([[[ 0.4159942 ,  0.44080812,  0.46027184, ...,\n",
      "          0.        ,  0.        ,  0.        ]],\n",
      "\n",
      "       [[ 0.        ,  0.        ,  0.        , ...,\n",
      "          0.        ,  0.        ,  0.        ]],\n",
      "\n",
      "       [[ 0.        ,  0.        ,  0.        , ...,\n",
      "          0.        ,  0.        ,  0.        ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.20830686, -0.22962488, -0.24940467, ...,\n",
      "          0.        ,  0.        ,  0.        ]],\n",
      "\n",
      "       [[ 0.        ,  0.        ,  0.        , ...,\n",
      "          0.        ,  0.        ,  0.        ]],\n",
      "\n",
      "       [[ 0.        ,  0.        ,  0.        , ...,\n",
      "          0.        ,  0.        ,  0.        ]]], dtype=float32)>, 'WHITENED_INJECTIONS': <tf.Tensor: shape=(8, 1, 2048), dtype=float32, numpy=\n",
      "array([[[-5.8463747e-03, -6.0640490e-03, -4.7045029e-03, ...,\n",
      "          1.4904801e-08, -1.4904801e-08, -7.4524005e-09]],\n",
      "\n",
      "       [[-1.8070157e-08, -1.8867400e-08,  1.1559659e-09, ...,\n",
      "          5.4986469e-09,  2.5076172e-08, -1.3208200e-09]],\n",
      "\n",
      "       [[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 1.6875819e-03,  1.9656485e-03,  2.2304931e-03, ...,\n",
      "          3.1626013e-03,  3.3274596e-03,  3.7140676e-03]],\n",
      "\n",
      "       [[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00]],\n",
      "\n",
      "       [[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00]]],\n",
      "      dtype=float32)>, 'INJECTION_MASKS': <tf.Tensor: shape=(1, 8), dtype=float32, numpy=array([[1., 0., 0., 0., 1., 1., 0., 0.]], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "# This is the data we will uses as an input examples to out model:\n",
    "print(f\"Dictionary to feed the model: \\n {input_data}\")\n",
    "\n",
    "# This is the target data we will use as labels to train our model:\n",
    "print(f\"Dictionary to use as the model labels: \\n {output_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then print some examples from this dataset to examine the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "len() of unsized object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 19\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Iterate over the multi-injections and their corresponding parameters.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m onsource_, injection, whitened_injection, masks_ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m     12\u001b[0m         onsource,\n\u001b[1;32m     13\u001b[0m         injections,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     ):\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# Create strain plots for each Phenom D and WNB injection with titles displaying the parameter values.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     generated_data_layout\u001b[38;5;241m.\u001b[39mappend([\n\u001b[0;32m---> 19\u001b[0m         gf\u001b[38;5;241m.\u001b[39mgenerate_strain_plot(\n\u001b[1;32m     20\u001b[0m             {\n\u001b[1;32m     21\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnsouce\u001b[39m\u001b[38;5;124m\"\u001b[39m: onsource_,\n\u001b[1;32m     22\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhitened Injection\u001b[39m\u001b[38;5;124m\"\u001b[39m: whitened_injection,\n\u001b[1;32m     23\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInjection\u001b[39m\u001b[38;5;124m\"\u001b[39m: injection,\n\u001b[1;32m     24\u001b[0m             },\n\u001b[1;32m     25\u001b[0m             height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m,\n\u001b[1;32m     26\u001b[0m             width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m800\u001b[39m,\n\u001b[1;32m     27\u001b[0m             title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExample Output. Has Injection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mbool\u001b[39m(masks_)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m         )\n\u001b[1;32m     29\u001b[0m     ])\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Arrange the plots in a grid layout and display them in the notebook.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m grid \u001b[38;5;241m=\u001b[39m gridplot(generated_data_layout)\n",
      "File \u001b[0;32m~/gravyflow/gravyflow/src/utils/plotting.py:167\u001b[0m, in \u001b[0;36mgenerate_strain_plot\u001b[0;34m(strain, sample_rate_hertz, title, colors, has_legend, scale_factor, height, width)\u001b[0m\n\u001b[1;32m    163\u001b[0m     curr_strain[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# --- FIX ENDS HERE ---\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# Get num samples and check dictionaries:\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m num_samples \u001b[38;5;241m=\u001b[39m check_ndarrays_same_length(curr_strain)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# Generate time axis for plotting:\u001b[39;00m\n\u001b[1;32m    170\u001b[0m time_axis \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0.0\u001b[39m, duration_seconds, num_samples)\n",
      "File \u001b[0;32m~/gravyflow/gravyflow/src/utils/plotting.py:80\u001b[0m, in \u001b[0;36mcheck_ndarrays_same_length\u001b[0;34m(my_dict)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe value for key \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not an np.ndarray.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Check the length of the ndarray:\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m current_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(value)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     first_length \u001b[38;5;241m=\u001b[39m current_length\n",
      "\u001b[0;31mTypeError\u001b[0m: len() of unsized object"
     ]
    }
   ],
   "source": [
    "# Extract the data from the generator output: \n",
    "onsource: tf.Tensor = input_data[gf.ReturnVariables.WHITENED_ONSOURCE.name]\n",
    "injections: tf.Tensor = output_data[gf.ReturnVariables.INJECTIONS.name]\n",
    "whitened_injections: tf.Tensor = output_data[gf.ReturnVariables.WHITENED_INJECTIONS.name]\n",
    "injection_masks: tf.Tensor = output_data[gf.ReturnVariables.INJECTION_MASKS.name][0]\n",
    "\n",
    "# Initialize an empty layout for the strain plots.\n",
    "generated_data_layout: List = []\n",
    "\n",
    "# Iterate over the multi-injections and their corresponding parameters.\n",
    "for onsource_, injection, whitened_injection, masks_ in zip(\n",
    "        onsource,\n",
    "        injections,\n",
    "        whitened_injections,\n",
    "        injection_masks\n",
    "    ):\n",
    "    # Create strain plots for each Phenom D and WNB injection with titles displaying the parameter values.\n",
    "    generated_data_layout.append([\n",
    "        gf.generate_strain_plot(\n",
    "            {\n",
    "                \"Onsouce\": onsource_,\n",
    "                \"Whitened Injection\": whitened_injection,\n",
    "                \"Injection\": injection,\n",
    "            },\n",
    "            height=400,\n",
    "            width=800,\n",
    "            title=f\"Example Output. Has Injection: {bool(masks_)}\"\n",
    "        )\n",
    "    ])\n",
    "\n",
    "# Arrange the plots in a grid layout and display them in the notebook.\n",
    "grid = gridplot(generated_data_layout)\n",
    "output_notebook()\n",
    "show(grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gravyflow2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
