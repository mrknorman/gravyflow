{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fb362f8",
   "metadata": {},
   "source": [
    "# Notebook 1: Setting up the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4127ab3b",
   "metadata": {},
   "source": [
    "## Sharing is caring\n",
    "\n",
    "Assuming you will be using GravyFlow on a shared GPU compute cluster, it is important to select the appropriate GPU(s) before executing any programs. This introductory notebook will guide you in configuring GravyFlow to automatically select a GPU with available memory. It will also ensure your environment is properly set up for running GravyFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf67322",
   "metadata": {},
   "source": [
    "## Notebook imports\n",
    "\n",
    "First, we will import a few built-in packages (os, sys) along with a key dependency, TensorFlow. These imports will be utilized in various sections of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6b3d964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-20 09:49:58.876438: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Importing the os module, which provides functions for interacting with the operating system.\n",
    "# This can be used for file and directory operations, environment variable management, etc.\n",
    "import os\n",
    "\n",
    "# Importing List from the typing module. Typehints can be used to illustrate to the reader of the\n",
    "# code the type of variables, in this case, lists.\n",
    "from typing import List\n",
    "\n",
    "# Importing TensorFlow, a powerful library for machine learning and neural networks.\n",
    "# Renamed as 'tf' for ease of use in the code.\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dd8239",
   "metadata": {},
   "source": [
    "## Import GravyFlow\n",
    "\n",
    "Next, we will import the GravyFlow module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feccc33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the GravyFlow module and rename it as 'gf' for ease of use in the code.\n",
    "import gravyflow as gf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c64bc5",
   "metadata": {},
   "source": [
    "## GPU Setup\n",
    "\n",
    "For ease of use, GravyFlow includes a function, `gf.env`, designed to automatically configure the GPU environment.\n",
    "\n",
    "The `gf.env` function has the following optional arguments:\n",
    "\n",
    "- `min_gpu_memory_mb` : int = 4000\n",
    "\t> Sets the minimum GPU memory (in megabytes) required for a GPU to be considered available for GravyFlow.\n",
    "- `max_gpu_utilization_percentage` : float = 80\n",
    "\t> Specifies the maximum GPU utilization (as a percentage) before GravyFlow disallows its use. The default is 80%.\n",
    "- `num_gpus_to_request` : int = 1\n",
    "\t> Determines the number of GPUs GravyFlow will try to find and use. The default is 1.\n",
    "- `memory_to_allocate_tf` : int = 2000\n",
    "\t> Sets the amount of GPU memory (in megabytes) that GravyFlow allocates per GPU. This value is fixed to ensure that CUDA functions run efficiently. Default is 2000 Mb.\n",
    "- `gpus` : Union[str, int, List[Union[int, str]], None] = None\n",
    "\t> Allows manual allocation on specified GPUs. This is not recommended unless necessary. If set to None, GravyFlow automatically selects free GPUs.\n",
    "\n",
    "The function returns the following object:\n",
    "\n",
    "- `strategy` : tf.distribute.Strategy: \n",
    "\t> Enables multi-GPU usage in subsequent TensorFlow operations.\n",
    "\n",
    "### Function Operations\n",
    "\n",
    "When called, `gf.env` performs several operations:\n",
    "\n",
    "1. Identifies available GPUs with free memory exceeding `min_gpu_memory_mb`.\n",
    "2. Allocates a specified number of GPUs (`num_gpus_to_request`) for GravyFlow and PhenomD, setting the `CUDA_VISIBLE_DEVICES` environment variable accordingly.\n",
    "3. Checks for compatibility between the CUDA and TensorFlow versions.\n",
    "4. Allocates `memory_to_allocate_tf` Mb of GPU memory to TensorFlow per requested GPU.\n",
    "5. Sets up and returns a `tf.distribute.Strategy` object for multi-GPU operations in TensorFlow.\n",
    "\n",
    "### Example Usage\n",
    "\n",
    "Below is an example of how to use `gf.env`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db7298c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:TensorFlow version: 2.12.1, CUDA version: 11.8\n",
      "2024-08-20 09:50:18.225281: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2024-08-20 09:50:18.225458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3000 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:0a:00.0, compute capability: 7.0\n",
      "INFO:root:[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_VISIBLE_DEVICES after environment setup: 2\n",
      "GPUs visible to TensorFlow after environment setup: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Set up the environment using gf.env() and return a tf.distribute.Strategy object.\n",
    "env : tf.distribute.Strategy = gf.env()\n",
    "\n",
    "with env:\n",
    "    # All code within this block will be executed under the TensorFlow strategy scope.\n",
    "\n",
    "    # Printing the CUDA_VISIBLE_DEVICES environment variable after gf.env() setup.\n",
    "    # This shows which GPUs are allocated for TensorFlow operations.\n",
    "    cuda_visible_devices : str = os.environ.get('CUDA_VISIBLE_DEVICES', 'Not set.')\n",
    "    print(f'CUDA_VISIBLE_DEVICES after environment setup: {cuda_visible_devices}')\n",
    "\n",
    "    # Printing the list of GPUs visible to TensorFlow after gf.env() has been executed.\n",
    "    # This confirms the successful allocation and visibility of GPUs to TensorFlow.\n",
    "    gpus : List = tf.config.list_physical_devices('GPU')\n",
    "    print(f\"GPUs visible to TensorFlow after environment setup: {gpus}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bd5057",
   "metadata": {},
   "source": [
    "## Important Notes on Using gf.env:\n",
    "\n",
    "Running any TensorFlow functionality before initializing the environment will cause it to run on all GPUs by default.\n",
    "You cannot set up the environment more than once per Python kernel session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccbe5cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:TensorFlow version: 2.12.1, CUDA version: 11.8\n",
      "INFO:root:[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_VISIBLE_DEVICES after environment setup: 5,6. This has changed correctly.\n",
      "GPUs visible to TensorFlow after environment setup: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]. This has not changed.\n"
     ]
    }
   ],
   "source": [
    "# Attempt to run gf.env again, this time requesting 2 GPUs, without restarting the kernel.\n",
    "env : tf.distribute.Strategy = gf.env(num_gpus_to_request=2)\n",
    "\n",
    "# gf.env will prevent the creation of a new scope, as TensorFlow does not allow this,\n",
    "# and will return the same environment that was set up initially.\n",
    "with env:\n",
    "    # Fetching and printing the CUDA_VISIBLE_DEVICES environment variable.\n",
    "    # This check is to see if the environment variable has changed.\n",
    "    cuda_visible_devices : str = os.environ.get('CUDA_VISIBLE_DEVICES', 'Not set.')\n",
    "    print(f'CUDA_VISIBLE_DEVICES after environment setup: {cuda_visible_devices}. This has changed correctly.')\n",
    "\n",
    "    # Fetching and printing the list of GPUs visible to TensorFlow.\n",
    "    # This is to verify if the visible GPUs to TensorFlow have changed.\n",
    "    gpus : List = tf.config.list_physical_devices('GPU')\n",
    "    print(f\"GPUs visible to TensorFlow after environment setup: {gpus}. This has not changed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3562e506",
   "metadata": {},
   "source": [
    "Now that we have seen how to automatically set up the environment, let's move on to acquiring our first interferometer noise background dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('gravyflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "0be68b4d857a3b55dcb84670c9ea8054a433650dc9da871ef592f2f480116ffb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}