{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model with a GravyFlow Dataset\n",
    "\n",
    "In this notebook we will use our generated dataset to train a keras model. We start with the needed imports: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2025-12-07 13:06:07,859:jax._src.xla_bridge:812: Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n",
      "2025-12-07 13:06:07,859 - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n",
      "W1207 13:06:09.671928 2204553 cuda_executor.cc:1802] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "W1207 13:06:09.672523 2204548 cuda_executor.cc:1802] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "W1207 13:06:09.672784 2204549 cuda_executor.cc:1802] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "W1207 13:06:09.673236 2204550 cuda_executor.cc:1802] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "W1207 13:06:09.673409 2204546 cuda_executor.cc:1802] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "W1207 13:06:09.674514 2204547 cuda_executor.cc:1802] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "W1207 13:06:09.687222 2204552 cuda_executor.cc:1802] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "W1207 13:06:09.698895 2204551 cuda_executor.cc:1802] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "W1207 13:06:09.713923 2204178 cuda_executor.cc:1802] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "W1207 13:06:09.714502 2204178 cuda_executor.cc:1802] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "W1207 13:06:09.715086 2204178 cuda_executor.cc:1802] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "W1207 13:06:09.716091 2204178 cuda_executor.cc:1802] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "W1207 13:06:09.716707 2204178 cuda_executor.cc:1802] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "W1207 13:06:09.717233 2204178 cuda_executor.cc:1802] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "W1207 13:06:09.717857 2204178 cuda_executor.cc:1802] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "W1207 13:06:09.718367 2204178 cuda_executor.cc:1802] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'jax'\n",
    "\n",
    "# Built-in imports\n",
    "from typing import List, Dict\n",
    "from pathlib import Path\n",
    "\n",
    "# Dependency imports: \n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import ops\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from keras.layers import Input, Permute, Conv1D, MaxPooling1D, Dense, Flatten, Dropout, ELU\n",
    "from keras.models import Model\n",
    "\n",
    "# Import the GravyFlow module.\n",
    "import gravyflow as gf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a TensorFlow dataset through composition:\n",
    "\n",
    "Rather than generating a generic Python iterator, we can also use GravyFlow to create a custom TensorFlow dataset. This will give us the ability to utalise all the functionality provided by the TensorFlow dataset class, including seamless integration with keras models, whilst maintaining the ability to generate datasets quickly enough for real time training, only caching downloaded data segments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will create a keras model, inspired by a model from the literature, found at Gabbard _et at._ here: https://link.aps.org/doi/10.1103/PhysRevLett.120.141103:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gabbard(\n",
    "        input_shape_onsource : int, \n",
    "        input_shape_offsource : int\n",
    "    ) -> keras.Model:\n",
    "    \n",
    "    # Define the inputs based on the dictionary keys and expected shapes\n",
    "    # Replace `input_shape_onsource` and `input_shape_offsource` with the actual shapes\n",
    "    onsource_input = Input(shape=input_shape_onsource, name=\"ONSOURCE\")\n",
    "    offsource_input = Input(shape=input_shape_offsource, name=\"OFFSOURCE\")\n",
    "\n",
    "    # Pass the inputs to your custom Whiten layer\n",
    "    # Assuming your Whiten layer can handle multiple inputs\n",
    "    whiten_output = gf.Whiten()([onsource_input, offsource_input])\n",
    "\n",
    "    x = Permute((2, 1))(whiten_output)\n",
    "    \n",
    "    # Convolutional and Pooling layers\n",
    "    x = Conv1D(8, 64, padding='valid', name=\"Convolutional_1\")(x)\n",
    "    x = ELU(name=\"ELU_1\")(x)\n",
    "    x = MaxPooling1D(pool_size=4, strides=4, name=\"Pooling_1\", padding=\"valid\")(x)\n",
    "    \n",
    "    x = Conv1D(8, 32, padding='valid', name=\"Convolutional_2\")(x)\n",
    "    x = ELU(name=\"ELU_2\")(x)\n",
    "    x = Conv1D(16, 32, padding='valid', name=\"Convolutional_3\")(x)\n",
    "    x = ELU(name=\"ELU_3\")(x)\n",
    "    x = MaxPooling1D(pool_size=4, strides=4, name=\"Pooling_3\", padding=\"valid\")(x)\n",
    "    \n",
    "    # Flatten layer\n",
    "    x = Flatten(name=\"Flatten\")(x)\n",
    "    \n",
    "    # Dense layers with dropout\n",
    "    x = Dense(64, name=\"Dense_1\")(x)\n",
    "    x = ELU(name=\"ELU_7\")(x)\n",
    "    x = Dropout(0.5, name=\"Dropout_1\")(x)\n",
    "    \n",
    "    x = Dense(64, name=\"Dense_2\")(x)\n",
    "    x = ELU(name=\"ELU_8\")(x)\n",
    "    x = Dropout(0.5, name=\"Dropout_2\")(x)\n",
    "    \n",
    "    outputs = Dense(1, activation='sigmoid', name=gf.ReturnVariables.INJECTION_MASKS.name)(x)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(\n",
    "        inputs=[onsource_input, offsource_input], \n",
    "        outputs={gf.ReturnVariables.INJECTION_MASKS.name: outputs}, \n",
    "        name=\"custom\"\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are only using one injection, we expect our output label to be a single value for each example, therefore we must adjust the dimensionality of the injection masks output with tensorflow datasets mapping functionality, we define the function we want to map to the dataset here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdapterDataset(keras.utils.PyDataset):\n",
    "    def __init__(self, dataset):\n",
    "        super().__init__(workers=dataset.workers, use_multiprocessing=dataset.use_multiprocessing)\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        features, labels = self.dataset[index]\n",
    "        if 'INJECTION_MASKS' in labels:\n",
    "            mask = labels['INJECTION_MASKS']\n",
    "            # Check if already processed: (Batch, 1)\n",
    "            if len(mask.shape) == 2 and mask.shape[1] == 1:\n",
    "                pass\n",
    "            elif len(mask.shape) == 2: # (NumGenerators, Batch)\n",
    "                mask = mask[0]\n",
    "                mask = ops.expand_dims(mask, axis=-1)\n",
    "            elif len(mask.shape) == 3: # (NumGenerators, Batch, Time)\n",
    "                mask = mask[0]\n",
    "                mask = jnp.max(mask, axis=-1)\n",
    "                mask = ops.expand_dims(mask, axis=-1)\n",
    "            \n",
    "            labels['INJECTION_MASKS'] = mask\n",
    "        return features, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow and keras requires that the model and training dataset are created in the same scope, and is quite strict about these limitations. Thus we will here create our dataset and our model in the same scope. Nominally, it is anticipated that GravyFlow will mostly be used in Python scripts, rather than notebooks, where this will not be a problem if everything is kept in the same TensorFlow strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-07 13:06:11,513 - INFO - Validating SciToken with jti: https://cilogon.org/oauth2/74a27edc3406eacca927215205620ba3?type=accessToken&ts=1765131015701&version=v2.0&lifetime=10800000\n",
      "2025-12-07 13:06:12,134 - INFO - Loading event times from cache.\n",
      "2025-12-07 13:06:13,210 - INFO - Validating SciToken with jti: https://cilogon.org/oauth2/74a27edc3406eacca927215205620ba3?type=accessToken&ts=1765131015701&version=v2.0&lifetime=10800000\n",
      "2025-12-07 13:06:13,952 - INFO - Loading event times from cache.\n",
      "2025-12-07 13:06:14,042 - INFO - Validating SciToken with jti: https://cilogon.org/oauth2/74a27edc3406eacca927215205620ba3?type=accessToken&ts=1765131015701&version=v2.0&lifetime=10800000\n",
      "2025-12-07 13:06:14,700 - INFO - Loading event times from cache.\n",
      "2025-12-07 13:06:14,961 - INFO - Finding URLs for L-L1_HOFT_C01 in interval [1242384384.1, 1242386157.9), ext='gwf', urltype='file', match=None\n",
      "2025-12-07 13:06:14,970 - INFO - Validating SciToken with jti: https://cilogon.org/oauth2/74a27edc3406eacca927215205620ba3?type=accessToken&ts=1765131015701&version=v2.0&lifetime=10800000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"custom\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"custom\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ ONSOURCE            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ OFFSOURCE           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32768</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ whiten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Whiten</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ONSOURCE[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ OFFSOURCE[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ permute (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Permute</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ whiten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Convolutional_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1985</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │ permute[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ELU_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ELU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1985</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Convolutional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Pooling_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">496</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ELU_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Convolutional_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">465</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,056</span> │ Pooling_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ELU_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ELU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">465</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Convolutional_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Convolutional_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">434</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,112</span> │ ELU_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ELU_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ELU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">434</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Convolutional_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Pooling_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">108</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ELU_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1728</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Pooling_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │    <span style=\"color: #00af00; text-decoration-color: #00af00\">110,656</span> │ Flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ELU_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ELU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ELU_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ Dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ELU_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ELU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ELU_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ INJECTION_MASKS     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ Dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ ONSOURCE            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m4096\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ OFFSOURCE           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32768\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ whiten (\u001b[38;5;33mWhiten\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ ONSOURCE[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ OFFSOURCE[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ permute (\u001b[38;5;33mPermute\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ whiten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Convolutional_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1985\u001b[0m, \u001b[38;5;34m8\u001b[0m)   │        \u001b[38;5;34m520\u001b[0m │ permute[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mConv1D\u001b[0m)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ELU_1 (\u001b[38;5;33mELU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1985\u001b[0m, \u001b[38;5;34m8\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ Convolutional_1[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Pooling_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m496\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ ELU_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Convolutional_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m465\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │      \u001b[38;5;34m2,056\u001b[0m │ Pooling_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mConv1D\u001b[0m)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ELU_2 (\u001b[38;5;33mELU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m465\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ Convolutional_2[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Convolutional_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m434\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │      \u001b[38;5;34m4,112\u001b[0m │ ELU_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mConv1D\u001b[0m)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ELU_3 (\u001b[38;5;33mELU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m434\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ Convolutional_3[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Pooling_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m108\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ ELU_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1728\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ Pooling_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │    \u001b[38;5;34m110,656\u001b[0m │ Flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ELU_7 (\u001b[38;5;33mELU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ Dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ ELU_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ Dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ELU_8 (\u001b[38;5;33mELU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ Dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ ELU_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ INJECTION_MASKS     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ Dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">121,569</span> (474.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m121,569\u001b[0m (474.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">121,569</span> (474.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m121,569\u001b[0m (474.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "examples_per_epoch = int(1E5)\n",
    "num_validation_examples = int(1E4)\n",
    "num_testing_examples = int(1E4)\n",
    "steps_per_epoch = examples_per_epoch // gf.Defaults.num_examples_per_batch\n",
    "validation_steps = num_validation_examples // gf.Defaults.num_examples_per_batch\n",
    "testing_steps = num_testing_examples // gf.Defaults.num_examples_per_batch\n",
    "\n",
    "# This object will be used to obtain real interferometer data based on specified parameters.\n",
    "ifo_data_obtainer : gf.IFODataObtainer = gf.IFODataObtainer(\n",
    "    observing_runs=gf.ObservingRun.O3, # Specify the observing run (e.g., O3).\n",
    "    data_quality=gf.DataQuality.BEST,  # Choose the quality of the data (e.g., BEST).\n",
    "    data_labels=[                      # Define the types of data to include.\n",
    "        gf.DataLabel.NOISE, \n",
    "        gf.DataLabel.GLITCHES\n",
    "    ],\n",
    "    segment_order=gf.SegmentOrder.RANDOM, # Order of segment retrieval (e.g., RANDOM).\n",
    "    force_acquisition=True,               # Force the acquisition of new data.\n",
    "    cache_segments=False                  # Choose not to cache the segments.\n",
    ")\n",
    "\n",
    "# Initialize the noise generator wrapper:\n",
    "# This wrapper will use the ifo_data_obtainer to generate real noise based on the specified parameters.\n",
    "noise: gf.NoiseObtainer = gf.NoiseObtainer(\n",
    "    ifo_data_obtainer=ifo_data_obtainer, # Use the previously set up IFODataObtainer object.\n",
    "    noise_type=gf.NoiseType.REAL,        # Specify the type of noise as REAL.\n",
    "    ifos=gf.IFO.L1                       # Specify the interferometer (e.g., LIGO Livingston L1).\n",
    ")\n",
    "\n",
    "scaling_method : gf.ScalingMethod = gf.ScalingMethod(\n",
    "    value=gf.Distribution(\n",
    "        min_=8.0,\n",
    "        max_=15.0,\n",
    "        type_=gf.DistributionType.UNIFORM\n",
    "    ),\n",
    "    type_=gf.ScalingTypes.SNR\n",
    ")\n",
    "\n",
    "# Define a uniform distribution for the mass of the first object in solar masses.\n",
    "mass_1_distribution_msun : gf.Distribution = gf.Distribution(\n",
    "    min_=10.0, \n",
    "    max_=60.0, \n",
    "    type_=gf.DistributionType.UNIFORM\n",
    ")\n",
    "\n",
    "# Define a uniform distribution for the mass of the second object in solar masses.\n",
    "mass_2_distribution_msun : gf.Distribution = gf.Distribution(\n",
    "    min_=10.0, \n",
    "    max_=60.0, \n",
    "    type_=gf.DistributionType.UNIFORM\n",
    ")\n",
    "\n",
    "# Define a uniform distribution for the inclination of the binary system in radians.\n",
    "inclination_distribution_radians : gf.Distribution = gf.Distribution(\n",
    "    min_=0.0, \n",
    "    max_=np.pi, \n",
    "    type_=gf.DistributionType.UNIFORM\n",
    ")\n",
    "\n",
    "# Initialize a PhenomD waveform generator with the defined distributions.\n",
    "# This generator will produce waveforms with randomly varied masses and inclination angles.\n",
    "phenom_d_generator : gf.WaveformGenerator = gf.CBCGenerator(\n",
    "    mass_1_msun=mass_1_distribution_msun,\n",
    "    mass_2_msun=mass_2_distribution_msun,\n",
    "    inclination_radians=inclination_distribution_radians,\n",
    "    scaling_method=scaling_method,\n",
    "    injection_chance=0.5 # Set so half produced examples will not contain this signal\n",
    ")\n",
    "\n",
    "training_dataset  = gf.Dataset(       \n",
    "    noise_obtainer=noise,\n",
    "    waveform_generators=phenom_d_generator,\n",
    "    input_variables=[\n",
    "        gf.ReturnVariables.ONSOURCE, \n",
    "        gf.ReturnVariables.OFFSOURCE, \n",
    "    ],\n",
    "    output_variables=[\n",
    "        gf.ReturnVariables.INJECTION_MASKS\n",
    "    ]\n",
    ")\n",
    "\n",
    "validation_dataset  = gf.Dataset(       \n",
    "    noise_obtainer=noise,\n",
    "    waveform_generators=phenom_d_generator,\n",
    "    seed=1001, # Implement different seed to generate different waveforms,\n",
    "    group=\"validate\", # Ensure noise is pulled from those marked for validation.\n",
    "    input_variables=[\n",
    "        gf.ReturnVariables.ONSOURCE, \n",
    "        gf.ReturnVariables.OFFSOURCE, \n",
    "    ],\n",
    "    output_variables=[\n",
    "        gf.ReturnVariables.INJECTION_MASKS\n",
    "    ]\n",
    ")\n",
    "\n",
    "testing_dataset  = gf.Dataset(     \n",
    "    num_examples_per_batch = 32,  \n",
    "    noise_obtainer=noise,\n",
    "    waveform_generators=phenom_d_generator,\n",
    "    seed=1002, # Implement different seed to generate different waveforms,\n",
    "    group=\"test\", # Ensure noise is pulled from those marked for validation.\n",
    "    input_variables=[\n",
    "        gf.ReturnVariables.ONSOURCE, \n",
    "        gf.ReturnVariables.OFFSOURCE, \n",
    "    ],\n",
    "    output_variables=[\n",
    "        gf.ReturnVariables.INJECTION_MASKS\n",
    "    ]\n",
    ")\n",
    "\n",
    "for input_example, _ in [training_dataset[0]]:\n",
    "    input_shape_onsource = input_example[\"ONSOURCE\"].shape[1:]  # Exclude batch dimension    \n",
    "    input_shape_offsource = input_example[\"OFFSOURCE\"].shape[1:] \n",
    "\n",
    "model = create_gabbard(input_shape_onsource, input_shape_offsource)\n",
    "\n",
    "# Now you can print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Model compilation\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',  # Or any other loss function appropriate for your task\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "training_dataset = AdapterDataset(training_dataset)\n",
    "validation_dataset = AdapterDataset(validation_dataset)\n",
    "testing_dataset = AdapterDataset(testing_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the previous cell failed it is most likely because you attempted to run it twice within the same kernel session. The kernal must be restarted in order to generate a fresh TensorFlow stratergy and recompile the model.\n",
    "\n",
    "Finally, we can train the model with our generated dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m 169/1000\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 44ms/step - accuracy: 0.5372 - loss: 0.7712"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Number of epochs to train for\u001b[39;49;00m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m model.evaluate(\n\u001b[32m      8\u001b[39m     testing_dataset, \n\u001b[32m      9\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/gravyflow/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/gravyflow/lib/python3.13/site-packages/keras/src/backend/jax/trainer.py:450\u001b[39m, in \u001b[36mJAXTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    441\u001b[39m     state = \u001b[38;5;28mself\u001b[39m._get_jax_state(\n\u001b[32m    442\u001b[39m         trainable_variables=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    443\u001b[39m         non_trainable_variables=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    446\u001b[39m         purge_model_variables=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    447\u001b[39m     )\n\u001b[32m    448\u001b[39m     \u001b[38;5;28mself\u001b[39m._jax_state_synced = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m450\u001b[39m logs, state = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m (\n\u001b[32m    452\u001b[39m     trainable_variables,\n\u001b[32m    453\u001b[39m     non_trainable_variables,\n\u001b[32m    454\u001b[39m     optimizer_variables,\n\u001b[32m    455\u001b[39m     metrics_variables,\n\u001b[32m    456\u001b[39m ) = state\n\u001b[32m    458\u001b[39m \u001b[38;5;66;03m# Setting _jax_state enables callbacks to force a state\u001b[39;00m\n\u001b[32m    459\u001b[39m \u001b[38;5;66;03m# sync if they need to.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/gravyflow/lib/python3.13/site-packages/keras/src/backend/jax/trainer.py:257\u001b[39m, in \u001b[36mJAXTrainer._make_function.<locals>.iterator_step\u001b[39m\u001b[34m(state, iterator)\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34miterator_step\u001b[39m(state, iterator):\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m step_function(state, \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/gravyflow/lib/python3.13/site-packages/keras/src/backend/jax/trainer.py:1038\u001b[39m, in \u001b[36mJAXEpochIterator._prefetch_numpy_iterator\u001b[39m\u001b[34m(self, numpy_iterator)\u001b[39m\n\u001b[32m   1036\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m queue:\n\u001b[32m   1037\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m queue.popleft()\n\u001b[32m-> \u001b[39m\u001b[32m1038\u001b[39m     \u001b[43menqueue\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/gravyflow/lib/python3.13/site-packages/keras/src/backend/jax/trainer.py:1033\u001b[39m, in \u001b[36mJAXEpochIterator._prefetch_numpy_iterator.<locals>.enqueue\u001b[39m\u001b[34m(n)\u001b[39m\n\u001b[32m   1031\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34menqueue\u001b[39m(n=\u001b[32m2\u001b[39m):\n\u001b[32m   1032\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m itertools.islice(numpy_iterator, n):\n\u001b[32m-> \u001b[39m\u001b[32m1033\u001b[39m         queue.append(\u001b[43m_distribute_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/gravyflow/lib/python3.13/site-packages/keras/src/backend/jax/trainer.py:984\u001b[39m, in \u001b[36m_distribute_data\u001b[39m\u001b[34m(data, layouts)\u001b[39m\n\u001b[32m    978\u001b[39m     jax_dist_data_input = partial(\n\u001b[32m    979\u001b[39m         jax_distribution_lib.distribute_data_input,\n\u001b[32m    980\u001b[39m         batch_dim_name=distribution.batch_dim_name,\n\u001b[32m    981\u001b[39m     )\n\u001b[32m    982\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tree.map_structure(jax_dist_data_input, data, layouts)\n\u001b[32m--> \u001b[39m\u001b[32m984\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtree\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice_put\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/gravyflow/lib/python3.13/site-packages/keras/src/tree/tree_api.py:200\u001b[39m, in \u001b[36mmap_structure\u001b[39m\u001b[34m(func, none_is_leaf, *structures)\u001b[39m\n\u001b[32m    167\u001b[39m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mkeras.tree.map_structure\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmap_structure\u001b[39m(func, *structures, none_is_leaf=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    169\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Maps `func` through given structures.\u001b[39;00m\n\u001b[32m    170\u001b[39m \n\u001b[32m    171\u001b[39m \u001b[33;03m    Examples:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    198\u001b[39m \u001b[33;03m            `assert_same_structure`.\u001b[39;00m\n\u001b[32m    199\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtree_impl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mstructures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnone_is_leaf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnone_is_leaf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/gravyflow/lib/python3.13/site-packages/keras/src/tree/optree_impl.py:111\u001b[39m, in \u001b[36mmap_structure\u001b[39m\u001b[34m(func, none_is_leaf, *structures)\u001b[39m\n\u001b[32m    107\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m func(*args)\n\u001b[32m    109\u001b[39m map_func = func_with_check \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(structures) > \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m func\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptree\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtree_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mstructures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnone_is_leaf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnone_is_leaf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mkeras\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    113\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/gravyflow/lib/python3.13/site-packages/optree/ops.py:766\u001b[39m, in \u001b[36mtree_map\u001b[39m\u001b[34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[39m\n\u001b[32m    764\u001b[39m leaves, treespec = _C.flatten(tree, is_leaf, none_is_leaf, namespace)\n\u001b[32m    765\u001b[39m flat_args = [leaves] + [treespec.flatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rests]\n\u001b[32m--> \u001b[39m\u001b[32m766\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtreespec\u001b[49m\u001b[43m.\u001b[49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/gravyflow/lib/python3.13/site-packages/jax/_src/api.py:2839\u001b[39m, in \u001b[36mdevice_put\u001b[39m\u001b[34m(x, device, src, donate, may_alias)\u001b[39m\n\u001b[32m   2837\u001b[39m   dst_avals.append(aval)\n\u001b[32m   2838\u001b[39m   _check_sharding(aval, d)\n\u001b[32m-> \u001b[39m\u001b[32m2839\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrace_state_clean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   2840\u001b[39m   out_flat = dispatch._batched_device_put_impl(\n\u001b[32m   2841\u001b[39m       *x_flat, devices=device_flat, srcs=src_flat,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m   2842\u001b[39m       copy_semantics=copy_semantics, dst_avals=dst_avals)\n\u001b[32m   2843\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/gravyflow/lib/python3.13/site-packages/jax/_src/core.py:1422\u001b[39m, in \u001b[36mtrace_state_clean\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1421\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrace_state_clean\u001b[39m() -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1422\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace_ctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_top_level\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/gravyflow/lib/python3.13/site-packages/jax/_src/core.py:1293\u001b[39m, in \u001b[36mTracingContext.is_top_level\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1290\u001b[39m   \u001b[38;5;28mself\u001b[39m.trace = eval_trace\n\u001b[32m   1291\u001b[39m   \u001b[38;5;28mself\u001b[39m.axis_env = top_axis_env\n\u001b[32m-> \u001b[39m\u001b[32m1293\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mis_top_level\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m   1294\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.trace \u001b[38;5;129;01mis\u001b[39;00m eval_trace \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m   1295\u001b[39m           \u001b[38;5;28mself\u001b[39m.axis_env \u001b[38;5;129;01mis\u001b[39;00m top_axis_env)\n\u001b[32m   1297\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mset_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(\n",
    "    training_dataset,\n",
    "    epochs=10,  # Number of epochs to train for\n",
    "    validation_data=validation_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(\n",
    "    testing_dataset, \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gravyflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
