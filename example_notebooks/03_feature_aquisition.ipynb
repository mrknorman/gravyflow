{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19d56a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in imports:\n",
    "from typing import List\n",
    "from itertools import islice\n",
    "\n",
    "# Import GravyFlow:\n",
    "import gravyflow as gf\n",
    "\n",
    "# Dependency imports: \n",
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.layouts import gridplot, column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0931443",
   "metadata": {},
   "source": [
    "## Obtaining Transient Events\n",
    "\n",
    "To acquire data from specific gravitational wave events (transients), use `gf.TransientObtainer`. This works similarly to `gf.NoiseObtainer` but is specifically designed for acquiring data around known event times.\n",
    "\n",
    "### TransientObtainer\n",
    "\n",
    "**Parameters:**\n",
    "\n",
    "- `ifo_data_obtainer` : `gf.IFODataObtainer` (**required**):\n",
    "  > The IFODataObtainer configured for transient acquisition. Unlike `NoiseObtainer`, this parameter is mandatory. The `data_labels` should include `gf.DataLabel.EVENTS` or `gf.DataLabel.GLITCHES` (not `gf.DataLabel.NOISE`).\n",
    "\n",
    "- `ifos` : Union[`gf.IFO`, List[`gf.IFO`]] = `[gf.IFO.L1]`:\n",
    "  > List of interferometers to acquire data from.\n",
    "\n",
    "- `event_names` : Union[str, List[str]] = None:\n",
    "  > Optional event name(s) to fetch (e.g., `\"GW150914\"` or `[\"GW150914\", \"GW170817\"]`). If set, only data for these specific events will be returned, superseding the default behavior of returning all events. Event names must match those in GWTC catalogs.\n",
    "\n",
    "- `event_types` : `List[gf.EventType]` = `[gf.EventType.CONFIDENT]`:\n",
    "  > Filter by event confidence.\n",
    "  > **Options:**\n",
    "  > - `gf.EventType.CONFIDENT`: Confirmed detections (Default).\n",
    "  > - `gf.EventType.MARGINAL`: Marginal triggers/candidates.\n",
    "\n",
    "- `data_labels` : List[`gf.DataLabel`] = `[gf.DataLabel.EVENTS]`:\n",
    "  > Specifies which transient types to include. Must NOT include `gf.DataLabel.NOISE` (raises `ValueError`). For noise acquisition, use `gf.NoiseObtainer` instead.\n",
    "\n",
    "- `groups` : dict = `{\"all\": 1.0}`:\n",
    "  > Group splits for data partitioning. Defaults to a single \"all\" group (no train/val/test split), which is typical for transient evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5b3274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gravyflow as gf\n",
    "print(gf.__file__)\n",
    "import inspect\n",
    "print(inspect.signature(gf.IFODataObtainer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910e5789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The new unified IFODataObtainer factory handles everything.\n",
    "# It returns a TransientDataObtainer when DataLabel.NOISE is not present.\n",
    "transient_obtainer = gf.IFODataObtainer(\n",
    "    observing_runs=gf.ObservingRun.O3,\n",
    "    data_quality=gf.DataQuality.BEST,\n",
    "    data_labels=[gf.DataLabel.EVENTS],\n",
    "    force_acquisition=True,               # Force the acquisition of new data.\n",
    "    cache_segments=False,                 # Choose not to cache the segments.\n",
    "    event_names=[\"GW150914\", \"GW170817\"]  # Now passed directly here\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e90c2be",
   "metadata": {},
   "source": [
    "## Searching for Events\n",
    "\n",
    "GravyFlow provides a powerful `search_events` function to filter gravitational wave events from GWTC catalogs based on astrophysical properties, observing runs, and more.\n",
    "\n",
    "**Parameters:**\n",
    "\n",
    "- `source_type` : `Union[gf.SourceType, str]` = `None`:\n",
    "  > Filter by astrophysical source type. \n",
    "  > **Enums (Recommended):**\n",
    "  > - `gf.SourceType.BBH`: Binary Black Hole (both masses ≥ 3 M☉)\n",
    "  > - `gf.SourceType.BNS`: Binary Neutron Star (both masses < 3 M☉)\n",
    "  > - `gf.SourceType.NSBH`: Neutron Star - Black Hole (one < 3 M☉, one ≥ 3 M☉)\n",
    "  >\n",
    "  > **Strings (Supported):** `\"BBH\"`, `\"BNS\"`, `\"NSBH\"` (case-insensitive).\n",
    "\n",
    "- `observing_runs` : `List[gf.ObservingRun]` = `None`:\n",
    "  > Filter by specific observing runs (e.g., `[gf.ObservingRun.O3]`).\n",
    "\n",
    "- `mass1_range` : `tuple` = `None`:\n",
    "  > (min, max) range for primary mass in solar masses. Use `None` for unbounded limits. \n",
    "  > *Example:* `(30, None)` finds events with m1 > 30 M☉.\n",
    "\n",
    "- `mass2_range` : `tuple` = `None`:\n",
    "  > (min, max) range for secondary mass in solar masses.\n",
    "\n",
    "- `total_mass_range` : `tuple` = `None`:\n",
    "  > (min, max) range for total system mass (m1 + m2).\n",
    "\n",
    "- `distance_range` : `tuple` = `None`:\n",
    "  > (min, max) range for luminosity distance in Mpc.\n",
    "  > *Example:* `(None, 500)` finds events closer than 500 Mpc.\n",
    "\n",
    "- `name_contains` : `str` = `None`:\n",
    "  > Substring to search for in the event name (case-insensitive).\n",
    "  > *Example:* `\"GW17\"` matches all 2017 events.\n",
    "\n",
    "**Returns:**\n",
    "- `List[str]`: A list of event names matching all specified conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9567fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Examples\n",
    "\n",
    "#### 1. Filter by Source Type (Using Enums)\n",
    "\n",
    "# Find all Binary Neutron Star events\n",
    "bns_events = gf.search_events(source_type=gf.SourceType.BNS)\n",
    "print(bns_events)\n",
    "# Output: ['GW170817', 'GW190425']\n",
    "\n",
    "#### 2. Filter by Observing Run\n",
    "# Find all Binary Black Holes in O3\n",
    "o3_bbh = gf.search_events(\n",
    "    source_type=gf.SourceType.BBH,\n",
    "    observing_runs=[gf.ObservingRun.O3]\n",
    ")\n",
    "\n",
    "#### 3. Complex Physical Queries\n",
    "# Find heavy BBHs (Total Mass > 80 M☉) that are relatively close (< 1000 Mpc)\n",
    "heavy_nearby = gf.search_events(\n",
    "    source_type=gf.SourceType.BBH,\n",
    "    total_mass_range=(80, None),\n",
    "    distance_range=(None, 1000)\n",
    ")\n",
    "\n",
    "#### 4. Search by Name\n",
    "# Find all events from 2017\n",
    "events_2017 = gf.search_events(name_contains=\"GW17\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa1b399",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(gf.search_events(observing_runs=[gf.ObservingRun.O1])))\n",
    "print(len(gf.search_events(observing_runs=[gf.ObservingRun.O2])))\n",
    "print(len(gf.search_events(observing_runs=[gf.ObservingRun.O3])))\n",
    "print(len(gf.search_events(observing_runs=[gf.ObservingRun.O4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70678bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The unified factory now handles specific event names directly.\n",
    "# and ifos is passed when calling the obtainer instance.\n",
    "batch = next(gf.IFODataObtainer(\n",
    "    observing_runs=None,\n",
    "    data_quality=gf.DataQuality.BEST,\n",
    "    data_labels=[gf.DataLabel.EVENTS],\n",
    "    force_acquisition=True,\n",
    "    cache_segments=False,\n",
    "    event_names=[\"GW150914\", \"GW170817\"]  # Now passed directly to the factory\n",
    ")(\n",
    "    ifos=[gf.IFO.H1, gf.IFO.L1], # IFO selection moved here\n",
    "    scale_factor=1, \n",
    "    whiten=True, \n",
    "    crop=True\n",
    "))\n",
    "\n",
    "# Extract from dict (same as before)\n",
    "onsource = batch[gf.ReturnVariables.ONSOURCE]\n",
    "offsource = batch[gf.ReturnVariables.OFFSOURCE]\n",
    "gps_times = batch[gf.ReturnVariables.TRANSIENT_GPS_TIME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c873a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "gw150914_plot = gf.generate_strain_plot(\n",
    "    {\"Onsource Noise\": onsource[0]},\n",
    "    title=[\n",
    "        f\"L1 Onsource GW150914\",\n",
    "        f\"H1 Onsource GW150914\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "gw170817_plot = gf.generate_strain_plot(\n",
    "    {\"Onsource Noise\": onsource[1]},\n",
    "    title=[\n",
    "        f\"L1 Onsource GW170817\",\n",
    "        f\"H1 Onsource GW170817\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "grid = gridplot([[gw150914_plot], [gw170817_plot]])\n",
    "output_notebook()\n",
    "show(grid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75285826",
   "metadata": {},
   "source": [
    "# Glitch Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a34618",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Available Glitch Types:\")\n",
    "glitch_types = list(gf.GlitchType)\n",
    "for glitch_type in glitch_types:\n",
    "    print(f\"  - {glitch_type.name}: '{glitch_type.value}'\")\n",
    "\n",
    "num_glitch_types = len(glitch_types)\n",
    "print(f\"\\nTotal: {num_glitch_types} glitch types\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771145de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure for glitch acquisition\n",
    "# IFODataObtainer acts as a factory and returns a TransientDataObtainer \n",
    "# because valid data_labels (GLITCHES) are provided.\n",
    "glitch_obtainer = gf.IFODataObtainer(\n",
    "    data_quality=gf.DataQuality.BEST,\n",
    "    data_labels=[gf.DataLabel.GLITCHES],\n",
    "    observing_runs=[gf.ObservingRun.O3],\n",
    "    saturation=1.0\n",
    ")\n",
    "\n",
    "# Create generator - get enough samples for all glitch types\n",
    "glitch_generator = glitch_obtainer(\n",
    "    sample_rate_hertz=2048.0,\n",
    "    onsource_duration_seconds=1.0,\n",
    "    offsource_duration_seconds=16.0,\n",
    "    num_examples_per_batch=num_glitch_types,  # One for each type\n",
    "    ifos=[gf.IFO.L1],     # IFOs must be passed here\n",
    "    scale_factor=1.0,     # No pre-scaling needed, whitening handles it\n",
    "    seed=42,\n",
    "    crop=True,            # Remove padding from onsource\n",
    "    whiten=True           # Apply whitening\n",
    ")\n",
    "\n",
    "# Get batch of glitches\n",
    "print(\"\\nAcquiring glitches...\")\n",
    "try:\n",
    "    # Glitch generator returns dict\n",
    "    batch = next(glitch_generator)\n",
    "    onsource = batch[gf.ReturnVariables.ONSOURCE]\n",
    "    offsource = batch[gf.ReturnVariables.OFFSOURCE]\n",
    "    gps_times = batch[gf.ReturnVariables.TRANSIENT_GPS_TIME]\n",
    "    label = batch.get(gf.ReturnVariables.GLITCH_TYPE)\n",
    "    print(f\"Acquired {onsource.shape[0]} glitch samples\")\n",
    "    print(f\"Onsource shape: {onsource.shape}\")\n",
    "    print(f\"Offsource shape: {offsource.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error acquiring glitches: {e}\")\n",
    "    # Optional: Print traceback to see details\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    onsource = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336d8cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating One-of-Each Glitch Plots (Optimized)...\n",
      "DEBUG: Found 6609 Air_Compressor glitches for L1\n",
      "DEBUG: Found 25013 Blip glitches for L1\n",
      "DEBUG: Found 7291 Extremely_Loud glitches for L1\n",
      "DEBUG: Found 758 Helix glitches for L1\n",
      "DEBUG: Found 14052 Koi_Fish glitches for L1\n",
      "DEBUG: Found 905 Light_Modulation glitches for L1\n",
      "DEBUG: Found 19829 Low_Frequency_Burst glitches for L1\n",
      "DEBUG: Found 14931 Low_Frequency_Lines glitches for L1\n",
      "DEBUG: Found 26778 None_of_the_Above glitches for L1\n",
      "DEBUG: Found 5584 Paired_Doves glitches for L1\n",
      "DEBUG: Found 2669 Power_Line glitches for L1\n",
      "DEBUG: Found 2362 Repeating_Blips glitches for L1\n",
      "DEBUG: Found 89715 Scattered_Light glitches for L1\n",
      "DEBUG: Found 294 Scratchy glitches for L1\n",
      "DEBUG: Found 28412 Tomte glitches for L1\n",
      "DEBUG: Found 2171 Violin_Mode glitches for L1\n",
      "DEBUG: Found 6596 Whistle glitches for L1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Initialize internal structures manually to avoid full iteration overhead\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# CORRECTED METHOD NAME: build_feature_index\u001b[39;00m\n\u001b[32m     18\u001b[39m index = obtainer.build_feature_index(ifos=[gf.IFO.L1], seed=\u001b[32m42\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m cache, _ = \u001b[43mobtainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_initialize_transient_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mIFO\u001b[49m\u001b[43m.\u001b[49m\u001b[43mL1\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2048.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m16.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# 2. Select one example of each target type\u001b[39;00m\n\u001b[32m     22\u001b[39m target_types = [\n\u001b[32m     23\u001b[39m     gt \u001b[38;5;28;01mfor\u001b[39;00m gt \u001b[38;5;129;01min\u001b[39;00m gf.GlitchType \n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gt \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [gf.GlitchType.CHIRP, gf.GlitchType.NO_GLITCH, gf.GlitchType.WANDERING_LINE]\n\u001b[32m     25\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gravyflow/gravyflow/src/dataset/acquisition/transient.py:1156\u001b[39m, in \u001b[36mTransientDataObtainer._initialize_transient_cache\u001b[39m\u001b[34m(self, ifos, sample_rate_hertz, onsource_duration_seconds, offsource_duration_seconds, enable_chunked_mode, chunk_size)\u001b[39m\n\u001b[32m   1154\u001b[39m         meta = cache.get_metadata()\n\u001b[32m   1155\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m meta[\u001b[33m'\u001b[39m\u001b[33mnum_glitches\u001b[39m\u001b[33m'\u001b[39m] > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1156\u001b[39m             \u001b[43mcache\u001b[49m\u001b[43m.\u001b[49m\u001b[43menable_chunked_mode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m                \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m                \u001b[49m\u001b[43msample_rate_hertz\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_rate_hertz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m                \u001b[49m\u001b[43monsource_duration\u001b[49m\u001b[43m=\u001b[49m\u001b[43monsource_duration_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m                \u001b[49m\u001b[43moffsource_duration\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffsource_duration_seconds\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1163\u001b[39m     logger.warning(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCache incompatible: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Resetting.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gravyflow/gravyflow/src/dataset/acquisition/cache.py:453\u001b[39m, in \u001b[36mDiskCache.enable_chunked_mode\u001b[39m\u001b[34m(self, chunk_size, sample_rate_hertz, onsource_duration, offsource_duration)\u001b[39m\n\u001b[32m    445\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34menable_chunked_mode\u001b[39m(\n\u001b[32m    446\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    447\u001b[39m     chunk_size: \u001b[38;5;28mint\u001b[39m = \u001b[32m5000\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    450\u001b[39m     offsource_duration: \u001b[38;5;28mfloat\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    451\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    452\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Enable chunked memory mode for faster cache hits.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cache\u001b[49m\u001b[43m.\u001b[49m\u001b[43menable_chunked_mode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_rate_hertz\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_rate_hertz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m        \u001b[49m\u001b[43monsource_duration\u001b[49m\u001b[43m=\u001b[49m\u001b[43monsource_duration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m        \u001b[49m\u001b[43moffsource_duration\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffsource_duration\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gravyflow/gravyflow/src/dataset/features/glitch_cache.py:660\u001b[39m, in \u001b[36mTransientCache.enable_chunked_mode\u001b[39m\u001b[34m(self, chunk_size, sample_rate_hertz, onsource_duration, offsource_duration)\u001b[39m\n\u001b[32m    657\u001b[39m \u001b[38;5;28mself\u001b[39m._chunk_in_memory = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    659\u001b[39m \u001b[38;5;66;03m# Load first chunk centered at index 0\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m660\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_chunk_around_index\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    662\u001b[39m logger.info(\n\u001b[32m    663\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEnabled chunked mode: chunk_size=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchunk_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    664\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtotal_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.get_metadata()[\u001b[33m'\u001b[39m\u001b[33mnum_glitches\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    665\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gravyflow/gravyflow/src/dataset/features/glitch_cache.py:701\u001b[39m, in \u001b[36mTransientCache._load_chunk_around_index\u001b[39m\u001b[34m(self, target_idx)\u001b[39m\n\u001b[32m    699\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m h5py.File(\u001b[38;5;28mself\u001b[39m.path, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    700\u001b[39m     grp = f[\u001b[33m'\u001b[39m\u001b[33mglitches\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m     \u001b[38;5;28mself\u001b[39m._chunk_onsource = \u001b[43mgrp\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43monsource\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    702\u001b[39m     \u001b[38;5;28mself\u001b[39m._chunk_offsource = grp[\u001b[33m'\u001b[39m\u001b[33moffsource\u001b[39m\u001b[33m'\u001b[39m][start:end]\n\u001b[32m    703\u001b[39m     \u001b[38;5;28mself\u001b[39m._chunk_gps = grp[\u001b[33m'\u001b[39m\u001b[33mgps_times\u001b[39m\u001b[33m'\u001b[39m][start:end]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:54\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:55\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/gravyflow/lib/python3.13/site-packages/h5py/_hl/dataset.py:840\u001b[39m, in \u001b[36mDataset.__getitem__\u001b[39m\u001b[34m(self, args, new_dtype)\u001b[39m\n\u001b[32m    838\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fast_read_ok \u001b[38;5;129;01mand\u001b[39;00m (new_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    839\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m840\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fast_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    841\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    842\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall back to Python read pathway below\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f8a396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating One-of-Each Glitch Plots (Optimized)...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TransientDataObtainer' object has no attribute '_build_transient_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      9\u001b[39m obtainer = gf.IFODataObtainer(\n\u001b[32m     10\u001b[39m     data_quality=gf.DataQuality.BEST,\n\u001b[32m     11\u001b[39m     data_labels=[gf.DataLabel.GLITCHES], \n\u001b[32m     12\u001b[39m     observing_runs=[gf.ObservingRun.O3], \n\u001b[32m     13\u001b[39m     saturation=\u001b[32m1.0\u001b[39m\n\u001b[32m     14\u001b[39m )\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Initialize internal structures manually to avoid full iteration overhead\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m index = \u001b[43mobtainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_build_transient_index\u001b[49m(ifos=[gf.IFO.L1], seed=\u001b[32m42\u001b[39m)\n\u001b[32m     18\u001b[39m cache, _ = obtainer._initialize_transient_cache([gf.IFO.L1], \u001b[32m2048.0\u001b[39m, \u001b[32m1.0\u001b[39m, \u001b[32m16.0\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# 2. Select one example of each target type\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'TransientDataObtainer' object has no attribute '_build_transient_index'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gravyflow as gf\n",
    "from bokeh.layouts import column\n",
    "from bokeh.io import output_notebook, show\n",
    "\n",
    "print(\"Generating One-of-Each Glitch Plots (Optimized)...\")\n",
    "\n",
    "# 1. Initialize ONE obtainer for ALL types (Metadata query & Cache load happens ONCE)\n",
    "obtainer = gf.IFODataObtainer(\n",
    "    data_quality=gf.DataQuality.BEST,\n",
    "    data_labels=[gf.DataLabel.GLITCHES], \n",
    "    observing_runs=[gf.ObservingRun.O3], \n",
    "    saturation=1.0\n",
    ")\n",
    "\n",
    "# Initialize internal structures manually to avoid full iteration overhead\n",
    "# CORRECTED METHOD NAME: build_feature_index\n",
    "index = obtainer.build_feature_index(ifos=[gf.IFO.L1], seed=42)\n",
    "cache, _ = obtainer._initialize_transient_cache([gf.IFO.L1], 2048.0, 1.0, 16.0)\n",
    "\n",
    "# 2. Select one example of each target type\n",
    "target_types = [\n",
    "    gt for gt in gf.GlitchType \n",
    "    if gt not in [gf.GlitchType.CHIRP, gf.GlitchType.NO_GLITCH, gf.GlitchType.WANDERING_LINE]\n",
    "]\n",
    "examples = {}\n",
    "\n",
    "for segment in index.iter(shuffle=True, seed=42):\n",
    "    if segment.kind in target_types and segment.kind not in examples:\n",
    "        examples[segment.kind] = segment\n",
    "    if len(examples) == len(target_types):\n",
    "        break\n",
    "\n",
    "plots = []\n",
    "\n",
    "# 3. Fetch and plot\n",
    "for glitch_type, segment in examples.items():\n",
    "    print(f\"Processing {glitch_type.name}...\")\n",
    "    \n",
    "    # Fast internal cache lookup\n",
    "    onsource, _, source = obtainer._get_sample_from_cache(\n",
    "        cache,\n",
    "        segment.transient_gps_time,\n",
    "        2048.0,\n",
    "        1.0, \n",
    "        16.0,\n",
    "        gps_key=segment.gps_key,\n",
    "        target_ifos=[\"L1\"]\n",
    "    )\n",
    "    \n",
    "    if onsource is not None:\n",
    "        plot = gf.generate_strain_plot(\n",
    "            strain={\"L1\": np.asarray(onsource[0])},\n",
    "            sample_rate_hertz=2048.0,\n",
    "            title=f\"{glitch_type.name} (GPS: {segment.transient_gps_time:.1f})\",\n",
    "            has_legend=False,\n",
    "            height=150, width=800\n",
    "        )\n",
    "        plots.append(plot)\n",
    "\n",
    "if plots:\n",
    "    layout = column(*plots)\n",
    "    output_notebook()\n",
    "    show(layout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gravyflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
